{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc0242cf-2544-495c-a204-d9a3b540e29e",
   "metadata": {},
   "source": [
    "# I. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0ec0dc-ac79-456c-9ab4-2508a2956dc6",
   "metadata": {},
   "source": [
    "## 1. Domain-specific area (rewrite)\n",
    "In this work, we present a text classifier for detecting fake news. Fake news, also known as misinformation, refers to false or misleading information presented as if it were real news. It has become a major issue in recent years, with the proliferation of social media platforms and the ease with which false information can be disseminated. The negative impact of fake news cannot be understated, as it can lead to harm to individuals and society as a whole.\n",
    "\n",
    "To address this problem, we have developed a machine learning-based text classifier that can accurately identify fake news articles. The classifier is trained on a large dataset of real and fake news articles, and uses various features of the text, such as word counts and sentiment, to make predictions.\n",
    "\n",
    "We evaluate the performance of the classifier using several metrics, and show that it is able to achieve high accuracy in detecting fake news. We also discuss the potential applications of the classifier, including its use by news organizations to fact-check articles, and by social media platforms to combat the spread of fake news."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76187fc-0793-450d-970f-b54dc129f3b3",
   "metadata": {},
   "source": [
    "## 2. Objectives (add references)\n",
    "This project aims to find a suitable way to perform text classification in news articles in order to classify if the article is or is not fake news. In order to adapt ourselves to the social media era and avoid the spread of misinformation we need to improve the ways we validate what is truth and what is not. Historically, we've seen that fake news can contribute to problems such as:\n",
    "1. Damaging the reputation of people through spreading misinformaiton. [reference]\n",
    "2. Advertise false propaganda in order to misguide elections and/or election results. [reference]\n",
    "3. Generate confirmation bias manipulating one's perception of reality. [reference]\n",
    "4. Estimulating conflicts in a situation where polarity is arising in society. [reference]\n",
    "\n",
    "We've also seen the widespread of fake news during COVID which, according to studies [reference], have been one of the causes of vaccine hesitancy, which has lead to unnecessary deaths all over the world.\n",
    "\n",
    "This work consists in an automated way to fact-check news in order to tackle the problems above and many more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c6e39f-9a77-44c6-97e2-5fee1e4e8982",
   "metadata": {},
   "source": [
    "## 3. Dataset\n",
    "\n",
    "### 3.1. Description\n",
    "In this work we will explore a dataset consisting of two CSV files containing classified fake and real news and we will use it to train our Machine Learning Model in order to be able to evaluate and classify other news. The language is english and the dataset consists of the following features:\n",
    "1. title: The title of the news article.\n",
    "2. text: The article itself.\n",
    "3. subject: Examples of a subject could be: politics, middle-east and news.\n",
    "4. date: The date that the article was published.\n",
    "### 3.2. Dataset size\n",
    "The first CSV file called 'True.csv' holding the articles categorized as not fake news consists of 21417 articles. The second one called 'Fake.csv' consists of 23481 articles.\n",
    "### 3.3. Data types\n",
    "All the data types are strings, except for the last column in the dataset which is a Date.\n",
    "### 3.4. Source\n",
    "Source: 'Fake and real news - Classifying the news' taken from kaggle. [link]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba24599-6576-4b84-9d56-bd60b1ce0ac8",
   "metadata": {},
   "source": [
    "## 4. Evaluation methodology\n",
    "\n",
    "For the evaluation of the model the technique being used here is accuracy, since it is a simple and quick way to give a perspective of the performance in one single number and also very easy to use with the classification algorithm we are using (logistic regression). We are using numpy to calculate that based on the results of the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe30b9f6-e173-4f5a-8d24-eada7dda741b",
   "metadata": {},
   "source": [
    "# II. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f123f17-216c-44ce-8d0a-63d4fdd988d5",
   "metadata": {},
   "source": [
    "## 5. Preprocessing\n",
    "\n",
    "### 5.1. Text representation\n",
    "As for the text representation and lexical analysis we are using a Word2Vec model with the gensim library. The reason we decided to use this is due to the fact that it keeps information about the ordering of the words in the vector, which is going to be useful to later analyze the bigrams (words that keep appearing together) which can be informative in order to understand properties of fake news articles.\n",
    "### 5.2 Pre-processing the data\n",
    "As for the preprocessing and text normalization step, we are using the following techniques:\n",
    "1. Tokenizing\n",
    "Using nltk to separate each sentence into tokens.\n",
    "2. Removing stopwords\n",
    "We are also using nltk's stopwords list for the english vocabulary in order to remove words that have no meaning (such as 'is' and 'are').\n",
    "\n",
    "### 5.3 File type format\n",
    "As per the file type format, the raw data is in two CSV files, which will then be added labels and merged in order to extract the features for the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36564ecd-8746-4ca7-bf52-063fc2cc3cb4",
   "metadata": {},
   "source": [
    "## Loading and inspect the dataset: https://www.kaggle.com/code/arund8888/titanic-classification-models-score-73\n",
    "TO DO:\n",
    "1. Create dataframes from CSVs (DONE)\n",
    "2. Add column label to both dataframes (DONE)\n",
    "3. Merge both the dataframes into one (DONE)\n",
    "4. Describe columns/find and fix missing data (is it worth it?)\n",
    "5. Plot two graphics: number of articles per subject and number of fake news per month/year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb0b88bc-2822-4442-9500-5201cc518047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pandas to load the dataset\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "fake_df = pd.read_csv('Fake.csv')\n",
    "true_df = pd.read_csv('True.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eddd8111-40da-4093-a082-6e8109cac896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12336</th>\n",
       "      <td>Mexico Senate committees pass controversial se...</td>\n",
       "      <td>MEXICO CITY (Reuters) - Mexican Senate committ...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>December 14, 2017</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>California attorney general to sue over Trump ...</td>\n",
       "      <td>SAN FRANCISCO (Reuters) - California Attorney ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>October 13, 2017</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17931</th>\n",
       "      <td>PRESIDENT TRUMP SLAM DUNKS Golden State NBA Pu...</td>\n",
       "      <td>In June of 2017, it was reported that the newl...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Sep 23, 2017</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16948</th>\n",
       "      <td>The American Energy Success Story Obama Won’t ...</td>\n",
       "      <td>Obama has waisted billions on green energy but...</td>\n",
       "      <td>Government News</td>\n",
       "      <td>Nov 29, 2015</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4700</th>\n",
       "      <td>Trump tells House leaders to cancel healthcare...</td>\n",
       "      <td>WASHINGTON (Reuters) - President Donald Trump ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>March 24, 2017</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19303</th>\n",
       "      <td>TREASURY DEPT Depicts Lady Liberty As A Black ...</td>\n",
       "      <td>Lady Liberty will be depicted as a black women...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Jan 15, 2017</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18189</th>\n",
       "      <td>WATCH: RACIST CONGRESSWOMAN MAXINE WATERS Won’...</td>\n",
       "      <td>Close your eyes and picture Speaker of the Hou...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Aug 7, 2017</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>Senior U.S. legal official meeting UK leaders ...</td>\n",
       "      <td>LONDON (Reuters) - A top U.S. government legal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>October 13, 2017</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20827</th>\n",
       "      <td>WOW! BRITISH ACTRESS HAMMERS EU Leaders: “Ever...</td>\n",
       "      <td>Outspoken British actress and columnist asks b...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Mar 23, 2016</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5666</th>\n",
       "      <td>According To Employees, Trump Often Spied On ...</td>\n",
       "      <td>If the way Donald Trump reportedly ran the Mar...</td>\n",
       "      <td>News</td>\n",
       "      <td>June 30, 2016</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "12336  Mexico Senate committees pass controversial se...   \n",
       "1263   California attorney general to sue over Trump ...   \n",
       "17931  PRESIDENT TRUMP SLAM DUNKS Golden State NBA Pu...   \n",
       "16948  The American Energy Success Story Obama Won’t ...   \n",
       "4700   Trump tells House leaders to cancel healthcare...   \n",
       "...                                                  ...   \n",
       "19303  TREASURY DEPT Depicts Lady Liberty As A Black ...   \n",
       "18189  WATCH: RACIST CONGRESSWOMAN MAXINE WATERS Won’...   \n",
       "1276   Senior U.S. legal official meeting UK leaders ...   \n",
       "20827  WOW! BRITISH ACTRESS HAMMERS EU Leaders: “Ever...   \n",
       "5666    According To Employees, Trump Often Spied On ...   \n",
       "\n",
       "                                                    text          subject  \\\n",
       "12336  MEXICO CITY (Reuters) - Mexican Senate committ...        worldnews   \n",
       "1263   SAN FRANCISCO (Reuters) - California Attorney ...     politicsNews   \n",
       "17931  In June of 2017, it was reported that the newl...        left-news   \n",
       "16948  Obama has waisted billions on green energy but...  Government News   \n",
       "4700   WASHINGTON (Reuters) - President Donald Trump ...     politicsNews   \n",
       "...                                                  ...              ...   \n",
       "19303  Lady Liberty will be depicted as a black women...        left-news   \n",
       "18189  Close your eyes and picture Speaker of the Hou...        left-news   \n",
       "1276   LONDON (Reuters) - A top U.S. government legal...     politicsNews   \n",
       "20827  Outspoken British actress and columnist asks b...        left-news   \n",
       "5666   If the way Donald Trump reportedly ran the Mar...             News   \n",
       "\n",
       "                     date  label  \n",
       "12336  December 14, 2017    True  \n",
       "1263    October 13, 2017    True  \n",
       "17931        Sep 23, 2017  False  \n",
       "16948        Nov 29, 2015  False  \n",
       "4700      March 24, 2017    True  \n",
       "...                   ...    ...  \n",
       "19303        Jan 15, 2017  False  \n",
       "18189         Aug 7, 2017  False  \n",
       "1276    October 13, 2017    True  \n",
       "20827        Mar 23, 2016  False  \n",
       "5666        June 30, 2016  False  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding a label to the true and fake dataframes so we can use the classifier next\n",
    "\n",
    "fake_df['label'] = 'False'\n",
    "true_df['label'] = 'True'\n",
    "\n",
    "# Merging the two dataframes into one (we are going to need this in order to train the model)\n",
    "data = pd.concat([fake_df, true_df])\n",
    "data\n",
    "\n",
    "# Shuffling the information\n",
    "data = data.sample(frac = 1)\n",
    "\n",
    "# Since there are too much rows (44898) in this dataframe and it is too costly to do operations such as iterate through it, I am going to use a subset of it\n",
    "data_copy = data.head(10000) # This is what we are going to be using from now on\n",
    "data_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ae9cb9-f519-4c4f-ad1d-c85594cafb5a",
   "metadata": {},
   "source": [
    "### Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95dfc9d5-a6c1-4998-8728-2c5fe14d6122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects:  ['News' 'left-news' 'politicsNews' 'politics' 'worldnews'\n",
      " 'Government News' 'US_News' 'Middle-east']\n"
     ]
    }
   ],
   "source": [
    "# Printing the unique subjects in each dataset\n",
    "print(\"Subjects: \", data_copy.subject.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d7a72ee-c286-4315-a51e-7211678e47fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: Index(['title', 'text', 'subject', 'date', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Printing the different columns\n",
    "print(\"Columns:\", data_copy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89d051ab-219d-44d8-81d3-75d153491860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the number of fake news per subject\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "# data['subject']\n",
    "# plt.figure(figsize=(10,8))\n",
    "# sb.countplot(data[\"subject\"])\n",
    "# plt.title(\"News\")\n",
    "# plt.xlabel(\"Politics\")\n",
    "# plt.xlabel(\"Government News\")\n",
    "# plt.xlabel(\"left-news\")\n",
    "# plt.xlabel(\"US_News\")\n",
    "# plt.xlabel(\"Middle-east\")\n",
    "# plt.ylabel(\"politicsNews\")\n",
    "# plt.ylabel(\"worldnews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bc5593-4fbf-4203-b420-55ed7db4d72f",
   "metadata": {},
   "source": [
    "## Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bdfc1b6-9722-45d7-a65c-dd5008846fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE\n",
    "# Generating a list of sentences so that we can preprocess and analyze later\n",
    "fake_articles = fake_df['title']\n",
    "true_articles = true_df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0009c1a-fcb6-43d8-8168-0cc62ca934c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Preprocess the sentences\n",
    "def preprocess(sentences):\n",
    "    # Tokenize the sentences: transforming the whole string into a list of tokens. We need this for the Word2Vec model and for the classifier model\n",
    "    sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "    # Lowercase the words\n",
    "    sentences = [[word.lower() for word in sentence] for sentence in sentences]\n",
    "    # Removing stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "    sentences = [word for word in sentences if not word in stop_words]\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c9f9ed7-7bfe-4dda-94b6-289f78db6acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/65/v6ssklls6x5dnvkx1dq1vnjh0000gp/T/ipykernel_8404/3211253336.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_copy['clean_text'] = sentences;\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12336</th>\n",
       "      <td>Mexico Senate committees pass controversial se...</td>\n",
       "      <td>MEXICO CITY (Reuters) - Mexican Senate committ...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>December 14, 2017</td>\n",
       "      <td>True</td>\n",
       "      <td>[mexico, city, (, reuters, ), -, mexican, sena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>California attorney general to sue over Trump ...</td>\n",
       "      <td>SAN FRANCISCO (Reuters) - California Attorney ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>October 13, 2017</td>\n",
       "      <td>True</td>\n",
       "      <td>[san, francisco, (, reuters, ), -, california,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17931</th>\n",
       "      <td>PRESIDENT TRUMP SLAM DUNKS Golden State NBA Pu...</td>\n",
       "      <td>In June of 2017, it was reported that the newl...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Sep 23, 2017</td>\n",
       "      <td>False</td>\n",
       "      <td>[in, june, of, 2017, ,, it, was, reported, tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16948</th>\n",
       "      <td>The American Energy Success Story Obama Won’t ...</td>\n",
       "      <td>Obama has waisted billions on green energy but...</td>\n",
       "      <td>Government News</td>\n",
       "      <td>Nov 29, 2015</td>\n",
       "      <td>False</td>\n",
       "      <td>[obama, has, waisted, billions, on, green, ene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4700</th>\n",
       "      <td>Trump tells House leaders to cancel healthcare...</td>\n",
       "      <td>WASHINGTON (Reuters) - President Donald Trump ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>March 24, 2017</td>\n",
       "      <td>True</td>\n",
       "      <td>[washington, (, reuters, ), -, president, dona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20383</th>\n",
       "      <td>WATCH: INDOCTRINATED COLLEGE STUDENTS Are Stun...</td>\n",
       "      <td>Would Hillary s  every day Americans  answer t...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Jun 23, 2016</td>\n",
       "      <td>False</td>\n",
       "      <td>[would, hillary, s, every, day, americans, ans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5660</th>\n",
       "      <td>Trump administration tightens Iran sanctions, ...</td>\n",
       "      <td>WASHINGTON (Reuters) - The Trump administratio...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>February 2, 2017</td>\n",
       "      <td>True</td>\n",
       "      <td>[washington, (, reuters, ), -, the, trump, adm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20657</th>\n",
       "      <td>AMERICA IS HAMMERING TARGET: #BoycottTarget Pe...</td>\n",
       "      <td>Did Target really believe that 99.8% of Americ...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Apr 29, 2016</td>\n",
       "      <td>False</td>\n",
       "      <td>[did, target, really, believe, that, 99.8, %, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3396</th>\n",
       "      <td>Twitter Mocks The Hell Out Of Trump For Lates...</td>\n",
       "      <td>When Trump promised to  drain the swamp,  he s...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 15, 2016</td>\n",
       "      <td>False</td>\n",
       "      <td>[when, trump, promised, to, drain, the, swamp,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13974</th>\n",
       "      <td>WAS IRANIAN BUSINESSMAN FREED FROM JAIL After ...</td>\n",
       "      <td>Just before an Iranian-American businessman wa...</td>\n",
       "      <td>politics</td>\n",
       "      <td>May 6, 2016</td>\n",
       "      <td>False</td>\n",
       "      <td>[just, before, an, iranian-american, businessm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "12336  Mexico Senate committees pass controversial se...   \n",
       "1263   California attorney general to sue over Trump ...   \n",
       "17931  PRESIDENT TRUMP SLAM DUNKS Golden State NBA Pu...   \n",
       "16948  The American Energy Success Story Obama Won’t ...   \n",
       "4700   Trump tells House leaders to cancel healthcare...   \n",
       "20383  WATCH: INDOCTRINATED COLLEGE STUDENTS Are Stun...   \n",
       "5660   Trump administration tightens Iran sanctions, ...   \n",
       "20657  AMERICA IS HAMMERING TARGET: #BoycottTarget Pe...   \n",
       "3396    Twitter Mocks The Hell Out Of Trump For Lates...   \n",
       "13974  WAS IRANIAN BUSINESSMAN FREED FROM JAIL After ...   \n",
       "\n",
       "                                                    text          subject  \\\n",
       "12336  MEXICO CITY (Reuters) - Mexican Senate committ...        worldnews   \n",
       "1263   SAN FRANCISCO (Reuters) - California Attorney ...     politicsNews   \n",
       "17931  In June of 2017, it was reported that the newl...        left-news   \n",
       "16948  Obama has waisted billions on green energy but...  Government News   \n",
       "4700   WASHINGTON (Reuters) - President Donald Trump ...     politicsNews   \n",
       "20383  Would Hillary s  every day Americans  answer t...        left-news   \n",
       "5660   WASHINGTON (Reuters) - The Trump administratio...     politicsNews   \n",
       "20657  Did Target really believe that 99.8% of Americ...        left-news   \n",
       "3396   When Trump promised to  drain the swamp,  he s...             News   \n",
       "13974  Just before an Iranian-American businessman wa...         politics   \n",
       "\n",
       "                     date  label  \\\n",
       "12336  December 14, 2017    True   \n",
       "1263    October 13, 2017    True   \n",
       "17931        Sep 23, 2017  False   \n",
       "16948        Nov 29, 2015  False   \n",
       "4700      March 24, 2017    True   \n",
       "20383        Jun 23, 2016  False   \n",
       "5660    February 2, 2017    True   \n",
       "20657        Apr 29, 2016  False   \n",
       "3396    December 15, 2016  False   \n",
       "13974         May 6, 2016  False   \n",
       "\n",
       "                                              clean_text  \n",
       "12336  [mexico, city, (, reuters, ), -, mexican, sena...  \n",
       "1263   [san, francisco, (, reuters, ), -, california,...  \n",
       "17931  [in, june, of, 2017, ,, it, was, reported, tha...  \n",
       "16948  [obama, has, waisted, billions, on, green, ene...  \n",
       "4700   [washington, (, reuters, ), -, president, dona...  \n",
       "20383  [would, hillary, s, every, day, americans, ans...  \n",
       "5660   [washington, (, reuters, ), -, the, trump, adm...  \n",
       "20657  [did, target, really, believe, that, 99.8, %, ...  \n",
       "3396   [when, trump, promised, to, drain, the, swamp,...  \n",
       "13974  [just, before, an, iranian-american, businessm...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we are creating a new column in the dataframe called 'clean_text' and adding the results of the preprocess method\n",
    "\n",
    "sentences = data_copy['text']\n",
    "sentences = preprocess(sentences)\n",
    "\n",
    "data_copy['clean_text'] = sentences;\n",
    "data_copy.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b0d60b-147e-4eaf-9968-8f5f9b393da6",
   "metadata": {},
   "source": [
    "## Lexical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747bd082-540b-4153-a7aa-ac684f2a192a",
   "metadata": {},
   "source": [
    "## Text representation: Word2Vec (Re-do: https://www.kaggle.com/code/hamishdickson/training-and-plotting-word2vec-with-bigrams)\n",
    "TO DO:\n",
    "1. Generate the model according to the link\n",
    "2. Find a good way to plot the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1b9ad4-a453-4d2e-b4cb-d4abe7b4ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Create a Word2Vec model and train it on the preprocessed sentences\n",
    "fake_lexical_model = Word2Vec(preprocessed_fake_sentences, window=5, min_count=1, workers=4)\n",
    "fake_lexical_model.train(preprocessed_fake_sentences, total_examples=len(sentences), epochs=10)\n",
    "\n",
    "true_lexical_model = Word2Vec(preprocessed_true_sentences, window=5, min_count=1, workers=4)\n",
    "true_lexical_model.train(preprocessed_true_sentences, total_examples=len(sentences), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114b3ffb-0e1c-443e-84fa-45591a685ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the fake lexicalmodel\n",
    "\n",
    "# Length of the model:\n",
    "print(\"Model length: \", len(fake_lexical_model.wv.key_to_index))\n",
    "\n",
    "# how many dimensions?\n",
    "print(\"Model dimensions:\", len(fake_lexical_model.wv['embarrassing']))\n",
    "\n",
    "# Finding similar terms\n",
    "fake_lexical_model.wv.most_similar('corruption', topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7dcac4-e3f6-4501-83f3-26c3ec96b6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the true lexical model\n",
    "\n",
    "# Length of the model:\n",
    "print(\"Model length: \", len(true_lexical_model.wv.key_to_index))\n",
    "\n",
    "# how many dimensions?\n",
    "print(\"Model dimensions:\", len(true_lexical_model.wv['rating']))\n",
    "\n",
    "# Finding similar terms\n",
    "true_lexical_model.wv.most_similar('rating', topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b92487-fb32-42a4-b5f0-4d7e0e418394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "from gensim.models.phrases import Phrases, ENGLISH_CONNECTOR_WORDS\n",
    "# Create training corpus. Must be a sequence of sentences (e.g. an iterable or a generator).\n",
    "sentences = preprocessed_fake_sentences[:10]\n",
    "\n",
    "# Train a toy phrase model on our training corpus.\n",
    "phrase_model = Phrases(sentences, min_count=1, threshold=1, connector_words=ENGLISH_CONNECTOR_WORDS)\n",
    "\n",
    "# Apply the trained phrases model to a new, unseen sentence.\n",
    "new_sentence = preprocessed_fake_sentences[11:20]\n",
    "phrase_model[new_sentence]\n",
    "\n",
    "# The toy model considered \"trees graph\" a single phrase => joined the two\n",
    "# tokens into a single \"phrase\" token, using our selected `_` delimiter.\n",
    "# Apply the trained model to each sentence of a corpus, using the same [] syntax:\n",
    "for sent in phrase_model[sentences]:\n",
    "    pass\n",
    "\n",
    "# Update the model with two new sentences on the fly.\n",
    "# phrase_model.add_vocab([[\"hello\", \"world\"], [\"meow\"]])\n",
    "\n",
    "# Export the trained model = use less RAM, faster processing. Model updates no longer possible.\n",
    "frozen_model = phrase_model.freeze()\n",
    "\n",
    "# Apply the frozen model; same results as before:\n",
    "frozen_model[new_sentence]\n",
    "\n",
    "\n",
    "# # Save / load models.\n",
    "frozen_model.save(\"/tmp/my_phrase_model.pkl\")\n",
    "model_reloaded = Phrases.load(\"/tmp/my_phrase_model.pkl\")\n",
    "model_reloaded[preprocessed_fake_sentences[21:22]]  # apply the reloaded model to a sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a44d20d-a4fb-49c4-b15d-d9300d2336d8",
   "metadata": {},
   "source": [
    "## 7. Classification approach\n",
    "\n",
    "### 7.1 Features and Labels\n",
    "For the classifier we are using two features: the 'title' which in the dataframe is the representation of the article and the 'label' which is the feature that tells which articles are true or fake.\n",
    "\n",
    "### 7.2 Classifier\n",
    "For the classifier we are using the logistic regression algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917ed837-7e3a-4782-88b8-7b2df821618c",
   "metadata": {},
   "source": [
    "## Creating the model for the classifier\n",
    "TO DO:\n",
    "1. Make it work\n",
    "2. Add column 'prediction' to dataframe and add prediction information for each sentence\n",
    "3. Plot the number of fake news per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1767a2e2-3080-40c7-82cd-7e126932dc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake news classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Pre-process the data\n",
    "texts = data['text'].values\n",
    "labels = data['label'].values\n",
    "\n",
    "# Tokenize the texts\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.33, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "for x in range(10):\n",
    "    print(texts[x] + ' | ' + y_pred[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b21a2f-ee54-4780-ad01-147aff4a37c7",
   "metadata": {},
   "source": [
    "## 6. Baseline performance\n",
    "Describe and justify the baseline against which you are going to compare the performance\n",
    "of your chosen approach. This can be an already published baseline (e.g. cited in the\n",
    "literature) or the results of a basic algorithm that you implement yourself. The baseline\n",
    "should represent a meaningful benchmark for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443c32f4-2a96-47d7-b74e-1aea1039ed2b",
   "metadata": {},
   "source": [
    "## 8. Coding style\n",
    "Your code is expected to meet certain standards as described by accepted coding\n",
    "conventions. This includes code indentation, avoiding unnamed numerical constants and\n",
    "undue use of string literals, assigning meaningful names to variables and subroutines, etc.\n",
    "The code is expected to be fully commented, including variables, sub-routines and calls to\n",
    "library methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e5bfb8-0862-4d87-810a-8af55f89dba8",
   "metadata": {},
   "source": [
    "# III. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d3f331-e574-464f-83fb-e3b94414f74b",
   "metadata": {},
   "source": [
    "## 9. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5dd550-ea0f-4289-84fb-a147dd903291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ea0806-fb4b-4990-9c57-36f5bcf29f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the model above on new data\n",
    "\n",
    "# Pre-process the new data\n",
    "X_new = vectorizer.transform(true_sentences[10])\n",
    "\n",
    "# Use the model to make predictions on the new data\n",
    "y_pred = model.predict(X_new)\n",
    "\n",
    "# Print the predictions\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f966415-36fe-4211-aafe-3ce125ac0304",
   "metadata": {},
   "source": [
    "## 10. Summary and conclusions\n",
    "Provide a reflective evaluation of the project in light of your results. Describe its\n",
    "contributions to the problem area, and discuss the extent to which your solution is\n",
    "transferable to other domain-specific areas. Discuss the extent to which your approach can\n",
    "be replicated by others, e.g. using different programming languages, development\n",
    "environments, libraries and algorithms. Review the potential benefits and drawbacks of\n",
    "alternative approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06f1166-abec-4be4-a05c-c95462efa721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836f9de8-a253-4a5d-9baa-8e6cd10453ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
